{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mitoolspro as mtp\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from mitoolspro.project import Project\n",
    "from mitoolspro import economic_complexity as ec\n",
    "from mitoolspro.utils import RECALCULATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = Project.load(auto_load=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_db = mtp.databases.MainConnection(pr.get_path('raw_db_path'))\n",
    "db = mtp.databases.MainConnection(pr.get_path(\"database\"))\n",
    "cc = ec.name_converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OEC Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators_tablename = ec.create_data_name(pr.vars['data_id'], 'indicators')\n",
    "create_indicators_table = not mtp.databases.check_if_table(db, indicators_tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_indicators_table or RECALCULATE:\n",
    "    indicators_dfs = []\n",
    "    for year in pr.vars['years']:\n",
    "        indicators_df = mtp.databases.read_sql_table(raw_db, f'oec_hs_indicators_{year}')\n",
    "        indicators_df['Country'] = cc.convert(indicators_df['Country'], to='name_short', not_found=None)\n",
    "        indicators_dfs.append(indicators_df)\n",
    "    indicators_df = pd.concat(indicators_dfs, axis=0)\n",
    "    indicators_df = indicators_df[['Year', 'Indicator', 'Country', 'Measure']]\n",
    "    indicators_df = indicators_df.pivot(index=['Year', 'Country'], columns='Indicator', values='Measure').reset_index()\n",
    "    indicators_df.to_sql(indicators_tablename, db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_folder = pr.get_path(\"oecd_folder\")\n",
    "indicators_tablename = 'oecd_indicators'\n",
    "create_indicators_table = not mtp.databases.check_if_table(db, indicators_tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretty_string(row):\n",
    "    return f\"{row['INDICATOR']}_{row['SUBJECT']}_{row['MEASURE']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_map = {\n",
    "    'Year': 'Year',\n",
    "    'Country': 'Country', \n",
    "    'AIREMISSION_CO2_MLN_TONNE': 'CO2EmissionsMillionTons',\n",
    "    'AIREMISSION_CO2_TONNE_CAP': 'CO2EmissionsTonsCap',\n",
    "    'AIREMISSION_GHG_THND_TONNECO2': 'GHGEmissionskTonsCO2Eq',\n",
    "    'AIREMISSION_GHG_TONNE_CAP': 'GHGEmissionsTonsCap',\n",
    "    'AQUAPROD_TOT_USD': 'AquaProdTotalUSD',\n",
    "    'CROPYIELD_WHEAT_THND_TONNE': 'WheatYieldkTons', \n",
    "    'CROPYIELD_WHEAT_TONNE_HA': 'WheatYieldTonsperHA',\n",
    "    'ELECTRICITY_TOT_GWH': 'TotalElectricityGenGWh',\n",
    "    'FISHLAND_TOT_USD': 'FishlanTotalUSD',\n",
    "    'FORESTRESOURCE_USEINTENSITY_RT': 'ForestsUseIntensity',\n",
    "    'GDP_TOT_MLN_USD': 'GDPTotalMillUSD',\n",
    "    'GDP_TOT_USD_CAP': 'GDPTotalUSDCap',\n",
    "    'PRYENRGSUPPLY_TOT_TOE_1000USD': 'PrimaryESupplyTOEbykUSD',\n",
    "    'RENEWABLE_TOT_PC_PRYENRGSUPPLY': 'RenewETotalpctESupply',\n",
    "    'PRYENRGSUPPLY_TOT_MLN_TOE': 'EnergySupplyTotalMillToe'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_indicators_table or RECALCULATE:\n",
    "    csvs = [oecd_folder / f for f in oecd_folder.iterdir() if not f.name.startswith('.')]\n",
    "    dfs = {f: pd.read_csv(f) for f in csvs}\n",
    "\n",
    "    for f, df in dfs.items():\n",
    "        df['Indicator'] = df.apply(create_pretty_string, axis=1)\n",
    "        df = df[['TIME', 'LOCATION', 'Indicator', 'Value']]\n",
    "        df.columns = ['Year', 'Country', 'Indicator', 'Measure']\n",
    "        dfs[f] = df\n",
    "    df = pd.concat(list(dfs.values()), axis=0)\n",
    "    df['Country'] = cc.convert(df['Country'], to='short_name', not_found=None)\n",
    "    df = df.reset_index(drop=True).drop_duplicates()\n",
    "    df = df.pivot_table(index=['Year', 'Country'], columns='Indicator', values='Measure', aggfunc='first').reset_index()\n",
    "    df.columns = df.columns.map(cols_map)\n",
    "    df.to_sql(indicators_tablename, db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecological Footprint Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint_folder = pr.get_path(\"footprint_folder\")\n",
    "footprint_tablename = 'ecological_footprint'\n",
    "create_footprint_table = not mtp.databases.check_if_table(db, footprint_tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_footprint_table or RECALCULATE:\n",
    "    excels = [footprint_folder / f for f in footprint_folder.iterdir() if f.suffix == '.xlsx' and not f.name.startswith('.')]\n",
    "    footprint_dataframes = [pd.read_excel(f, index_col=0) for f in excels]\n",
    "    footprint = pd.concat(footprint_dataframes, axis=0)\n",
    "    footprint = footprint.loc[footprint['Record'] == 'EFConsTotGHA']\n",
    "    footprint['Country Name'] = cc.convert(footprint['Country Name'], to='name_short', not_found=None)\n",
    "    footprint = footprint.reset_index(drop=True)\n",
    "    footprint = footprint.rename(columns={'year': 'Year', 'Country Name': 'Country'})\n",
    "    footprint = footprint[[c for c in footprint.columns if c not in ['Short Name', 'Record', 'isoa2']]]\n",
    "    footprint.columns = [f\"{c} Eco Footprint\" if c not in ['Country', 'Year'] else c for c in footprint.columns]\n",
    "    footprint.to_sql(footprint_tablename, db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Bank Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_bank_folder = pr.get_path(\"wb_folder\")\n",
    "classification_tablename = 'income_classification'\n",
    "wbindicators_tablename = 'wb_indicators'\n",
    "create_classification_table = not mtp.databases.check_if_table(db, classification_tablename)\n",
    "create_wbindicators_table = not mtp.databases.check_if_table(db, wbindicators_tablename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_classification_table or RECALCULATE:\n",
    "    classification = pd.read_excel(world_bank_folder / 'OGHIST.xlsx', sheet_name='Country Analytical History', header=5).iloc[5:223, 1:]\n",
    "    classification = classification.melt(id_vars='Data for calendar year :', var_name=\"Year\", value_name=\"Income Level\")\n",
    "    classification.columns = ['Country', 'Year', 'Income Group']\n",
    "    classification['Income Group'] = classification['Income Group'].replace('*', '').map({\n",
    "        'L': 'Low income',\n",
    "        'LM': 'Lower middle income',\n",
    "        'UM': 'Upper middle income',\n",
    "        'H': 'High income'\n",
    "    })\n",
    "    classification['Country'] = cc.convert(names=classification['Country'], to='short_name')\n",
    "    classification.to_sql(classification_tablename, db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_wbindicators_table or RECALCULATE:\n",
    "    wbindicators_excel = '1990_2022_World_Development_Indicators.xlsx'\n",
    "    indicators = pd.read_excel(world_bank_folder / wbindicators_excel).iloc[:-5, :]\n",
    "    indicators['Country Name'] = cc.convert(names=indicators['Country Name'], to='short_name', not_found=None)\n",
    "    indicators = indicators[[c for c in indicators.columns if c not in ['Series Code']]]\n",
    "    indicators.columns = ['Country', 'Country Code', 'Indicator', *[str(year) for year in range(1990, 2023)]]\n",
    "    indicators = indicators.melt(id_vars=['Country', 'Country Code', 'Indicator'])\n",
    "    indicators.columns = ['Country', 'Country Code', 'Indicator', 'Year', 'Measure']\n",
    "    indicators = indicators[['Country', 'Indicator', 'Year', 'Measure']]\n",
    "    indicators = indicators.pivot(index=['Year', 'Country'], columns='Indicator', values='Measure').reset_index()\n",
    "    indicators = indicators.reset_index(drop=True)\n",
    "    indicators['Year'] = pd.to_numeric(indicators['Year'])\n",
    "    indicators = indicators.loc[indicators['Year'].isin(pr.vars['years'])].reset_index(drop=True)\n",
    "    indicators.to_sql(wbindicators_tablename, db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_world_bank_folder = pr.get_path(\"extra_wb_folder\")\n",
    "world_bank_tablename = 'extra_world_bank'\n",
    "create_world_bank_table = not mtp.databases.check_if_table(db, world_bank_tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_world_bank_table or RECALCULATE:\n",
    "    excel = [x for x in extra_world_bank_folder.iterdir() if x.suffix == '.xlsx' and not x.stem.startswith('.')][0]\n",
    "    world_bank = pd.read_excel(excel).replace('..', np.nan)\n",
    "    world_bank['Country Name'] = cc.convert(world_bank['Country Name'], to='name_short', not_found=None)\n",
    "    world_bank = world_bank.loc[world_bank['Country Name'].notna()]\n",
    "    world_bank = world_bank.set_index(['Series Name', 'Country Name']).drop(columns=['Country Code', 'Series Code'])\n",
    "    world_bank.columns = [c.split('[')[0] for c in world_bank.columns]\n",
    "    world_bank = world_bank.swaplevel('Country Name', 'Series Name', axis=0)\n",
    "    world_bank = world_bank.T\n",
    "    world_bank.columns.names = ['Country', 'Indicator']\n",
    "    world_bank.index.names = ['Year']\n",
    "    world_bank.index = world_bank.index.astype(int)\n",
    "    world_bank.stack(level=0).reset_index().to_sql(world_bank_tablename, db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal Credit Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_folder = pr.get_path(\"internal_credit\")\n",
    "internal_credit_tablename = 'internal_credit'\n",
    "create_credit_table = not mtp.databases.check_if_table(db, internal_credit_tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_credit_table or RECALCULATE:\n",
    "    excel = [x for x in credit_folder.iterdir() if x.suffix == '.xlsx'][0]\n",
    "    internal_credit = pd.read_excel(excel).replace('..', np.nan).iloc[:-5]\n",
    "    internal_credit = internal_credit.set_index(['Series Name', 'Country Name']).drop(columns=['Country Code', 'Series Code'])\n",
    "    internal_credit.columns = [c.split('[')[0] for c in internal_credit.columns]\n",
    "    internal_credit = internal_credit.swaplevel('Country Name', 'Series Name', axis=0)\n",
    "    internal_credit = internal_credit.T\n",
    "    internal_credit.columns.names = ['Country', 'Indicator']\n",
    "    internal_credit.columns = internal_credit.columns.set_levels(cc.convert(internal_credit.columns.get_level_values('Country'), to='name_short', not_found=None), level=0)\n",
    "    internal_credit.index = internal_credit.index.astype(int)\n",
    "    internal_credit.index.names = ['Year']\n",
    "    internal_credit.stack(level=0).reset_index().to_sql(internal_credit_tablename, db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental Patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_patents_folder = pr.get_path(\"environmental_patents\")\n",
    "environmental_patents_tablename = 'environmental_patents'\n",
    "create_env_patents_table = not mtp.databases.check_if_table(db, environmental_patents_tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_env_patents_table or RECALCULATE:\n",
    "    csv = [x for x in env_patents_folder.iterdir() if x.suffix == '.csv'][0]\n",
    "    environmental_patents = pd.read_csv(csv)\n",
    "    environmental_patents = environmental_patents.dropna(axis=1, how='all')\n",
    "    environmental_patents =  environmental_patents[['REF_AREA', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "    environmental_patents.columns = ['Country', 'Year', 'Environmental Patents']\n",
    "    environmental_patents = environmental_patents.groupby(['Country', 'Year']).sum()\n",
    "    environmental_patents.index = environmental_patents.index.set_levels(cc.convert(environmental_patents.index.levels[0], to='name_short', not_found=None), level=0)\n",
    "    environmental_patents = environmental_patents.reindex(pd.MultiIndex.from_product([environmental_patents.index.levels[0], range(1995, 2021)], names=environmental_patents.index.names))\n",
    "    environmental_patents = (environmental_patents.unstack(level=0)\n",
    "        .swaplevel(0, 1, axis=1)\n",
    "        .fillna(0.0))\n",
    "    environmental_patents.index = environmental_patents.index.astype(int)\n",
    "    environmental_patents.stack(level=0).reset_index().to_sql(environmental_patents_tablename, db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental Policy Stringency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_policy_folder = pr.get_path(\"policy_stringency\")\n",
    "envrionmental_policy_tablename = 'environmental_policy_stringency'\n",
    "create_environemtal_policy_table = not mtp.databases.check_if_table(db, envrionmental_policy_tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_environemtal_policy_table or RECALCULATE:\n",
    "    csv = [x for x in env_policy_folder.iterdir() if x.suffix == '.csv'][0]\n",
    "    policy_stringency = pd.read_csv(csv)\n",
    "    policy_stringency = policy_stringency.dropna(axis=1, how='all')\n",
    "    policy_stringency = policy_stringency[['Country', 'Year', 'Value']]\n",
    "    policy_stringency.columns = ['Country', 'Year', 'Environmental Policy Stringency']\n",
    "    policy_stringency['Country'] = cc.convert(policy_stringency['Country'], to='name_short', not_found=None)\n",
    "    policy_stringency = policy_stringency.set_index(['Country', 'Year'])\n",
    "    policy_stringency = policy_stringency.unstack(level=0).swaplevel(0, 1, axis=1).sort_index(axis=1)\n",
    "    policy_stringency.index = policy_stringency.index.astype(int)\n",
    "    policy_stringency.stack(level=0).reset_index().to_sql(envrionmental_policy_tablename, db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globalisation Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalisation_folder = pr.get_path(\"globalisation\")\n",
    "globalisation_index_tablename = 'globalisation_index'\n",
    "create_globalisation_index_table = not mtp.databases.check_if_table(db, globalisation_index_tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_globalisation_index_table or RECALCULATE:\n",
    "    dta = [x for x in globalisation_folder.iterdir() if x.suffix == '.dta'][0]\n",
    "    globalisation_index = pd.read_stata(dta)\n",
    "    vars_map = {\n",
    "        'KOFGI': 'Globalisation Index', \n",
    "        'KOFGIdf': 'Globalisation Index, de facto', \n",
    "        'KOFGIdj': 'Globalisation Index, de jure', \n",
    "        'KOFEcGI': 'Economic Globalisation',\n",
    "        'KOFEcGIdf': 'Economic Globalisation, de facto', \n",
    "        'KOFEcGIdj': 'Economic Globalisation, de jure', \n",
    "        'KOFTrGI': 'Trade Globalisation', \n",
    "        'KOFTrGIdf': 'Trade Globalisation, de facto', \n",
    "        'KOFTrGIdj': 'Trade Globalisation, de jure',\n",
    "        'KOFFiGI': 'Financial Globalisation', \n",
    "        'KOFFiGIdf': 'Financial Globalisation, de facto', \n",
    "        'KOFFiGIdj': 'Financial Globalisation, de jure', \n",
    "        'KOFSoGI': 'Social Globalisation', \n",
    "        'KOFSoGIdf': 'Social Globalisation, de facto',\n",
    "        'KOFSoGIdj': 'Social Globalisation, de jure', \n",
    "        'KOFIpGI': 'Interpersonal Globalisation', \n",
    "        'KOFIpGIdf': 'Interpersonal Globalisation, de facto', \n",
    "        'KOFIpGIdj': 'Interpersonal Globalisation, de jure', \n",
    "        'KOFInGI': 'Informational Globalisation',\n",
    "        'KOFInGIdf': 'Informational Globalisation, de facto', \n",
    "        'KOFInGIdj': 'Informational Globalisation, de jure', \n",
    "        'KOFCuGI': 'Cultural Globalisation', \n",
    "        'KOFCuGIdf': 'Cultural Globalisation, de facto', \n",
    "        'KOFCuGIdj': 'Cultural Globalisation, de jure',\n",
    "        'KOFPoGI': 'Political Globalisation', \n",
    "        'KOFPoGIdf': 'Political Globalisation, de facto', \n",
    "        'KOFPoGIdj': 'Political Globalisation, de jure',\n",
    "        'country': 'Country',\n",
    "        'year': 'Year'\n",
    "    }\n",
    "    globalisation_index.columns = globalisation_index.columns.map(vars_map)\n",
    "    globalisation_index = globalisation_index.iloc[:, 1:].set_index(['Country', 'Year'])\n",
    "    globalisation_index.index = globalisation_index.index.set_levels(cc.convert(globalisation_index.index.levels[0], to='name_short', not_found=None), level=0)\n",
    "    globalisation_index = globalisation_index.unstack(level=0).swaplevel(0, 1, axis=1).sort_index(axis=1)\n",
    "    globalisation_index = globalisation_index.loc[1995:2020, :]\n",
    "    globalisation_index.index = globalisation_index.index.astype(int)\n",
    "    globalisation_index.stack(level=0).reset_index().to_sql(globalisation_index_tablename, db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Inequality Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inequality_folder = pr.get_path(\"inequality\")\n",
    "income_inequality_tablename = 'income_inequality_index'\n",
    "create_income_inequality_table = not mtp.databases.check_if_table(db, income_inequality_tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_income_inequality_table or RECALCULATE:\n",
    "    countries_data = inequality_folder / 'WID_countries.csv'\n",
    "    countries_data = pd.read_csv(countries_data, delimiter=';')\n",
    "    countries_data = countries_data[['alpha2', 'shortname']]\n",
    "    countries_data.columns = ['alpha2', 'Country']\n",
    "    countries_data = countries_data.loc[countries_data['alpha2'].str.find('-') == -1]\n",
    "    valid_codes = countries_data['alpha2'].unique()\n",
    "    inequalities_data = [f for f in inequality_folder.iterdir() if f.suffix == '.csv' and '_data_' in f.stem and 'WID_countries' not in f.stem and not f.stem.startswith('.') and f.stem.split('_')[-1] in valid_codes]\n",
    "    inequalities_metadata = [f for f in inequality_folder.iterdir() if f.suffix == '.csv' and '_metadata_' in f.stem and 'WID_countries' not in f.stem and not f.stem.startswith('.') and f.stem.split('_')[-1] in valid_codes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left undone... No need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
