{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DYLD_FALLBACK_LIBRARY_PATH\"] = \"/opt/homebrew/lib:/opt/homebrew/opt/cairo/lib\" # :/\n",
    "import mitoolspro as mtp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from mitoolspro.project import Project\n",
    "from mitoolspro import economic_complexity as ec\n",
    "from mitoolspro.utils import RECALCULATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = Project.load(auto_load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = False\n",
    "validate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mtp.databases.MainConnection(pr.get_path(\"database\"))\n",
    "data_tablename = ec.create_data_name(pr.vars['data_id'], 'clean')\n",
    "data_file = pr.get_path(\"data_file\")\n",
    "hs_codes_tablename = 'hs_codes'\n",
    "hs_bridge_tablename = 'hs_bridge'\n",
    "hs_codes_file = pr.get_path('hs_codes')\n",
    "create_hs_bridge_table = not mtp.databases.check_if_table(db, hs_bridge_tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hs_codes_file.exists() or RECALCULATE:\n",
    "    hs_codes = pd.read_sql(f\"SELECT * FROM {hs_codes_tablename}\", db, index_col='index')\n",
    "    hs_codes = hs_codes[['Section', 'Section ID', 'HS2', 'HS2 ID', 'HS4', 'HS4 ID', 'HS6', 'HS6 ID']].drop_duplicates()\n",
    "    hs6 = hs_codes[['HS6 ID', 'HS6']].drop_duplicates()\n",
    "    hs_codes = hs_codes.loc[~hs6['HS6'].duplicated(keep='last')].reset_index(drop=True).sort_values(by=['Section ID', 'HS2 ID', 'HS4 ID', 'HS6 ID'])\n",
    "    hs_codes.to_parquet(hs_codes_file)\n",
    "else:\n",
    "    hs_codes = pd.read_parquet(hs_codes_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_file.exists() or RECALCULATE:\n",
    "    data = pd.read_sql(f'SELECT * FROM {data_tablename}', db)\n",
    "    data_sectors = data[['HS2', 'HS2 ID', 'HS4', 'HS4 ID', 'HS6', 'HS6 ID']].drop_duplicates()\n",
    "    duplicated_products = data_sectors.loc[data_sectors['HS6'].duplicated(keep=False), 'HS6'].unique()\n",
    "    id_map = hs_codes.loc[hs_codes['HS6'].isin(duplicated_products), ['HS6', 'HS6 ID']].set_index('HS6').to_dict()['HS6 ID']\n",
    "    data.loc[data['HS6'].isin(id_map.keys()), 'HS6 ID'] = data.loc[data['HS6'].isin(id_map.keys()), 'HS6'].map(id_map)\n",
    "    data = data.groupby(['Year', 'Section', 'Section ID', 'HS2', 'HS2 ID', 'HS4', 'HS4 ID', 'HS6', 'HS6 ID', 'Country', 'Country ID']).sum().reset_index()\n",
    "    # Make Electrical Energy exports equals to 0\n",
    "    data.loc[data['HS6'] == 'Electrical energy', ['Trade Value']] = 0.0\n",
    "    data = data.loc[data['Country'] != 'North Korea']\n",
    "    data.to_parquet(data_file)\n",
    "else:\n",
    "    data = pd.read_parquet(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pr.vars['countries']\n",
    "data = data.loc[data['Country'].isin(countries)]\n",
    "print('There are ', data['Country'].nunique(), ' considered countries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate Null Electrical Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The amount of exports in Electrical energy are: ', data.loc[data['HS6'] == 'Electrical energy', 'Trade Value'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.add_var('total_exports', data['Trade Value'].sum(), update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_hs_bridge_table or RECALCULATE:\n",
    "    hs_bridge = pd.read_excel(pr.get_path('sector_mapping'))\n",
    "    hs_bridge = hs_bridge.drop_duplicates()\n",
    "    hs_bridge.to_sql(hs_bridge_tablename, db, if_exists='replace')\n",
    "hs_bridge = pd.read_sql(f\"SELECT * FROM {hs_bridge_tablename}\", db, index_col='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize HS Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_bridge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_bridge.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Considered Sectors:')\n",
    "print('='*20)\n",
    "mtp.utils.functions.iprint(hs_bridge['Sector'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Products per Sector:')\n",
    "hs_bridge.groupby('Sector')['HS6'].count().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Map of IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mapping = {\n",
    "    'Section': 'Section ID',\n",
    "    'HS2': 'HS2 ID',\n",
    "    'HS4': 'HS4 ID',\n",
    "    'HS6': 'HS6 ID',\n",
    "    'Country': 'Country ID'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if any([col in data.columns for col in id_mapping.values()]) or RECALCULATE:\n",
    "    id_maps = {}\n",
    "    for col, id_col in id_mapping.items():\n",
    "        id_tablename = f'{col}_{id_col}_mapping'.replace(' ', '_')\n",
    "        id_map = data[[col, id_col]].drop_duplicates().reset_index(drop=True)\n",
    "        id_map.to_sql(id_tablename, db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Hs Bridge Map of IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_tablename = 'Sector_Sector_ID_mapping'\n",
    "if not mtp.databases.check_if_table(db, id_tablename) or RECALCULATE:\n",
    "    id_map = hs_bridge[['Sector']].drop_duplicates().reset_index(drop=True)\n",
    "    id_map['Sector ID'] = id_map.index + 1\n",
    "    id_map.to_sql(id_tablename, db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add HS Bridge to HS Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_mapping = hs_codes.merge(hs_bridge, on=['HS2', 'HS4', 'HS6'])\n",
    "sector_mapping = sector_mapping[[c for c in sector_mapping.columns if c.find('ID') == -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Sector' not in hs_codes.columns:\n",
    "    hs_codes = hs_codes.merge(sector_mapping, on=['Section', 'HS2', 'HS4', 'HS6'])\n",
    "    hs_codes['Sector ID'] = hs_codes['Sector'].map({code: n+1 for n, code in enumerate(hs_codes['Sector'].sort_values().unique())})\n",
    "    hs_codes.to_parquet(hs_codes_file)\n",
    "else:\n",
    "    hs_codes = pd.read_parquet(hs_codes_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge HS Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate:\n",
    "    print('Validation of Consistent Total Exports Amount:', pr.vars['total_exports'] == data['Trade Value'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Sector' not in data.columns or RECALCULATE:\n",
    "    data = data.merge(hs_codes, on=['Section', 'Section ID', 'HS2', 'HS2 ID', 'HS4', 'HS4 ID', 'HS6', 'HS6 ID'])\n",
    "    data = data[['Year', 'Section', 'Section ID', 'Sector', 'Sector ID', 'HS2', 'HS2 ID', 'HS4', 'HS4 ID', 'HS6', 'HS6 ID', 'Country', 'Country ID', 'Trade Value']]\n",
    "    data.to_parquet(data_file)\n",
    "else:\n",
    "    data = pd.read_parquet(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate:\n",
    "    print('Validation of Consistent Total Exports Amount:', pr.vars['total_exports'] == data['Trade Value'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop IDs from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if any([col in data.columns for col in id_mapping.values()]) or RECALCULATE:\n",
    "    data = data[['Year', 'Section', 'Section ID', 'Sector', 'Section ID', 'HS2', 'HS2 ID', 'HS4', 'HS4 ID', 'HS6', 'HS6 ID', 'Country', 'Country ID', 'Trade Value']]\n",
    "    data = data[[c for c in data.columns if c.find('ID') == -1]]\n",
    "    data.to_parquet(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation of Consistent Total Exports Amount:')\n",
    "pr.vars['total_exports'] == data['Trade Value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yearly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_data = {int(year): data[data['Year'] == year].reset_index(drop=True) for year in np.sort(data['Year'].unique())}\n",
    "yearly_data = {year: data.groupby(['Year', 'Section', 'Sector', 'HS2', 'HS4', 'HS6', 'Country']).sum().reset_index() for year, data in yearly_data.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exports Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_col = 'Country'\n",
    "products_col = ['Sector', 'HS2', 'HS4', 'HS6']\n",
    "value_col = 'Trade Value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_name = 'exports_matrices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = set(data['Country'].unique())\n",
    "if not mtp.pandas_utils.check_if_dataframe_sequence(pr.get_path('data'), sequence_name, pr.vars['years']) or RECALCULATE:\n",
    "    exports = {year: ec.exports_data_to_matrix(exports, origin_col, products_col, value_col, hs_codes) for year, exports in yearly_data.items()}\n",
    "    exports = {year: export.reindex(all_countries).fillna(0.0).sort_index() for year, export in exports.items()}\n",
    "    mtp.pandas_utils.store_dataframe_sequence(exports, sequence_name, pr.get_path('data'))\n",
    "else:\n",
    "    exports = mtp.pandas_utils.load_dataframe_sequence(pr.get_path('data'), sequence_name, pr.vars['years'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show:\n",
    "    ec.plots.display_rca_matrix(exports[2020])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Countries and Products Existence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_products = set([(sector, hs2, hs4, hs6) for _, (sector, hs2, hs4, hs6) in data[['Sector', 'HS2', 'HS4', 'HS6']].drop_duplicates().iterrows()])\n",
    "print('There are a total of: ', len(all_products), 'considered products.')\n",
    "print('There are a total of: ', len(all_countries), 'considered countries.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate:\n",
    "    for year, export in exports.items():\n",
    "        print('Validating data of ', year, '...')\n",
    "        assert all_countries == set(export.index), 'Not all countries'\n",
    "        assert all_products == set(export.columns), 'Not all products'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RCA Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_name = 'rca_matrices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not mtp.pandas_utils.check_if_dataframe_sequence(pr.get_path('data'), sequence_name, pr.vars['years'])  or RECALCULATE:\n",
    "    rcas = {year: ec.calculate_exports_matrix_rca(exports).sort_index() for year, exports in exports.items()}\n",
    "    mtp.pandas_utils.store_dataframe_sequence(rcas, sequence_name, pr.get_path('data'))\n",
    "else:\n",
    "    rcas = mtp.pandas_utils.load_dataframe_sequence(pr.get_path('data'), sequence_name, pr.vars['years'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show:\n",
    "    ec.plots.display_rca_matrix(rcas[2020])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked RCA Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_name = 'masked_rca_matrices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not mtp.pandas_utils.check_if_dataframe_sequence(pr.get_path('data'), sequence_name, pr.vars['years']) or RECALCULATE:\n",
    "    mrcas = {year: ec.mask_matrix(rca, 1.0).sort_index() for year, rca in rcas.items()}\n",
    "    mtp.pandas_utils.store_dataframe_sequence(mrcas, sequence_name, pr.get_path('data'))\n",
    "else:\n",
    "    mrcas = mtp.pandas_utils.load_dataframe_sequence(pr.get_path('data'), sequence_name, pr.vars['years'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show:\n",
    "    ec.plots.display_rca_matrix(mrcas[2020])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximity Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_name = 'proximity_matrices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not mtp.pandas_utils.check_if_dataframe_sequence(pr.get_path('data'), sequence_name, pr.vars['years']) or RECALCULATE:\n",
    "    proximities = {year: ec.calculate_proximity_matrix(mrca) for year, mrca in mrcas.items()}\n",
    "    mtp.pandas_utils.store_dataframe_sequence(proximities, sequence_name, pr.get_path('data'))\n",
    "else:\n",
    "    proximities = mtp.pandas_utils.load_dataframe_sequence(pr.get_path('data'), sequence_name, pr.vars['years'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show:\n",
    "    ec.plots.display_proximity_matrix(proximities[2020])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatedness Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_name = 'relatedness'\n",
    "file_name = pr.get_path(\"relatedness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not file_name.exists() or RECALCULATE:\n",
    "    relatedness = []\n",
    "    for (year, proximity), (_, rca) in zip(proximities.items(), rcas.items()):\n",
    "        yearly_relatedness = ec.calculate_relatedness_matrix(proximity, rca)\n",
    "        yearly_relatedness[\"Year\"] = year\n",
    "        yearly_relatedness = yearly_relatedness.set_index([\"Year\"], append=True)\n",
    "        relatedness.append(yearly_relatedness)\n",
    "    relatedness = pd.concat(relatedness)\n",
    "    relatedness = relatedness.reorder_levels([-1, -2, 0, 1, 2, 3], axis=0).sort_index()\n",
    "    relatedness.columns = [\"Relatedness\"]\n",
    "    relatedness.to_parquet(file_name)\n",
    "else:\n",
    "    relatedness = pd.read_parquet(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complexity Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "eci_frame_name = 'economic_complexity'\n",
    "eci_file_name = pr.get_path('economic_complexity')\n",
    "\n",
    "pci_frame_name = 'product_complexity'\n",
    "pci_file_name = pr.get_path('product_complexity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eci_file_name.exists() or not pci_file_name.exists() or RECALCULATE:\n",
    "    eci_frames, pci_frames = [], []\n",
    "    for year, rca in tqdm(mrcas.items()):\n",
    "        eci_frame, pci_frame = ec.calculate_economic_complexity(rca, standardize=False)\n",
    "        eci_frame[\"Year\"] = year\n",
    "        eci_frame = eci_frame.set_index([\"Year\"], append=True)\n",
    "        pci_frame[\"Year\"] = year\n",
    "        pci_frame = pci_frame.set_index([\"Year\"], append=True)\n",
    "        eci_frames.append(eci_frame)\n",
    "        pci_frames.append(pci_frame)\n",
    "    eci_frame = pd.concat(eci_frames, axis=0)\n",
    "    eci_frame = eci_frame.reorder_levels([1, 0], axis=0).sort_values(by=['Year', 'Country'])\n",
    "    eci_frame.to_parquet(eci_file_name)\n",
    "    pci_frame = pd.concat(pci_frames, axis=0)\n",
    "    pci_frame = pci_frame.reorder_levels([-1, 0, 1, 2, 3]).sort_values(by=['Year', 'Sector', 'HS2', 'HS4', 'HS6'])\n",
    "    pci_frame.to_parquet(pci_file_name)\n",
    "else:\n",
    "    eci_frame = pd.read_parquet(eci_file_name)\n",
    "    pci_frame = pd.read_parquet(pci_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reindex All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Year', 'Country', 'Sector', 'HS2', 'HS4', 'HS6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_index = pd.MultiIndex.from_tuples([(year, country,) + product for year, country, product in product(pr.vars['years'], all_countries, all_products)], names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_name = 'complexity_data'\n",
    "all_data_file = pr.get_path('complexity_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all_data_file.exists() or RECALCULATE:\n",
    "    data = data[[*columns, value_col]].set_index([c for c in data.columns if c not in [value_col, 'Section']]).reorder_levels([0, -1, 1, 2, 3, 4]).reindex(all_index, fill_value=0)\n",
    "    data.to_parquet(all_data_file)\n",
    "else:\n",
    "    data = pd.read_parquet(all_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sum().values[0] == pr.vars[\"total_exports\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Complexity Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all([c not in data.columns for c in eci_frame.columns]) and all([c not in data.columns for c in pci_frame.columns]):\n",
    "    data = data.merge(eci_frame, left_on=['Year', 'Country'], right_index=True, how='left')\n",
    "    data = data.merge(pci_frame, left_on=['Year', 'Sector', 'HS2', 'HS4', 'HS6'], right_index=True, how='left')\n",
    "    data.to_parquet(all_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Relatedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all([c not in data.columns for c in relatedness.columns]):\n",
    "    data = data.merge(relatedness, left_on=['Year', 'Country', 'Sector', 'HS2', 'HS4', 'HS6'], right_index=True, how='left')\n",
    "    data.to_parquet(all_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrca_frame_name = 'raw_rca'\n",
    "rrca_frame_file = pr.get_path('raw_rca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not rrca_frame_file.exists() or RECALCULATE:\n",
    "    rca = []\n",
    "    for year, dataframe in rcas.items():\n",
    "        dataframe = dataframe.stack(level=list(dataframe.columns.names), future_stack=True).reset_index(name=\"RCA\").set_index(['Country', 'Sector', 'HS2', 'HS4', 'HS6'])\n",
    "        dataframe = dataframe.reindex(set(all_index.droplevel('Year').tolist()), fill_value=0.0)\n",
    "        dataframe['Year'] = year\n",
    "        dataframe = dataframe.set_index(['Year'], append=True)\n",
    "        rca.append(dataframe)\n",
    "    rca = pd.concat(rca, axis=0).rename(columns={'RCA': 'rawRCA'})\n",
    "    rca = rca.reorder_levels([-1, 0, 1, 2, 3, 4])\n",
    "    rca = rca.sort_index()\n",
    "    rca.to_parquet(rrca_frame_file)\n",
    "else:\n",
    "    rca = pd.read_parquet(rrca_frame_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all([c not in data.columns for c in rca.columns]):\n",
    "    data = data.merge(rca, left_on=['Year', 'Country', 'Sector', 'HS2', 'HS4', 'HS6'], right_index=True, how='left')\n",
    "    data.to_parquet(all_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_frame_name = 'rca'\n",
    "rca_frame_file = pr.get_path('rca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not rca_frame_file.exists() or RECALCULATE:\n",
    "    rca = []\n",
    "    for year, dataframe in mrcas.items():\n",
    "        dataframe = dataframe.stack(level=list(dataframe.columns.names), future_stack=True).reset_index(name=\"RCA\").set_index(['Country', 'Sector', 'HS2', 'HS4', 'HS6'])\n",
    "        dataframe = dataframe.reindex(set(all_index.droplevel('Year').tolist()), fill_value=0.0)\n",
    "        dataframe['Year'] = year\n",
    "        dataframe = dataframe.set_index(['Year'], append=True)\n",
    "        rca.append(dataframe)\n",
    "    rca = pd.concat(rca, axis=0)\n",
    "    rca = rca.reorder_levels([-1, 0, 1, 2, 3, 4])\n",
    "    rca = rca.sort_index()\n",
    "    rca.to_parquet(rca_frame_file)\n",
    "else:\n",
    "    rca = pd.read_parquet(rca_frame_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all([c not in data.columns for c in rca.columns]):\n",
    "    data = data.merge(rca, left_on=['Year', 'Country', 'Sector', 'HS2', 'HS4', 'HS6'], right_index=True, how='left')\n",
    "    data.to_parquet(all_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Standardized ECI and PCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in data.index.get_level_values('HS6').unique() if 'Apple' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_group(group, col):\n",
    "    std = group[col].std()\n",
    "    mean = group[col].mean()\n",
    "    group[col] = (group[col] - mean) / std\n",
    "    return group[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PCI'] = data.groupby(by=['Year', 'Country']).apply(standardize_group, col='PCI').droplevel([0, 1]).to_frame()\n",
    "data['ECI'] = data.groupby(by=['Year', 'HS6']).apply(standardize_group, col='ECI').droplevel([0, 1]).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet(all_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate:\n",
    "    print('Validation of Consistent Total Exports Amount:', pr.vars['total_exports'] == data['Trade Value'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
